{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6 NN Real manufacturing data hands-on.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNVsvNP5WwnHwqa3mL21UMK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"N3Ij1FUL6VCN","colab_type":"text"},"source":["# Hands-on with real manufacturing data\n","\n","semiconducter company production data \n","\n","Labels:\n","\n","**-1** fail\n","\n"," **1** success\n","\n","---\n","\n","Data Set Characteristics: **Multivariate**\n","\n","Number of Instances: **1567**\n","\n","Area: **Computer**\n","\n","Attribute Characteristics: **Real**\n","\n","Number of Attributes: **591**\n","\n","Date Donated: **2008-11-19**\n","\n","Associated Tasks: **Classification, Causal-Discovery**\n","\n","Missing Values? **Yes**\n","\n","Authors: **Michael McCann**, **Adrian Johnston** "]},{"cell_type":"code","metadata":{"id":"aUYCi9CS6KbA","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","tf.random.set_seed(77)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W8jRQfiQ7nwZ","colab_type":"text"},"source":["**Import the data files to this colab instance**\n","\n","And load the data into dataframes"]},{"cell_type":"code","metadata":{"id":"vRi3Vi2u7mYE","colab_type":"code","colab":{}},"source":["df_data = pd.read_csv('secom.data', delimiter=' ', header=None)\n","df_label = pd.read_csv('secom_labels.data', delimiter=' ', header=None)\n","df_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qV72GFdkbxua","colab_type":"text"},"source":["Visual inspect the NaN values"]},{"cell_type":"code","metadata":{"id":"2KJdmO3u8tn4","colab_type":"code","colab":{}},"source":["plt.pcolor(df_data.isnull())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AwiUmTQl_aDA","colab_type":"text"},"source":["As we can see, there is alot of NaN values. we need to do somehting about this.\n","\n","But first we should split the dataset into train and test "]},{"cell_type":"code","metadata":{"id":"AsssCT58_1x6","colab_type":"code","colab":{}},"source":["x_train, x_test, y_train, y_test = train_test_split(df_data, df_label, test_size=0.20, random_state=77)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hHAFm94R_Zjr","colab_type":"code","colab":{}},"source":["print(f'Length of train data {len(x_train)}, test data {len(x_test)}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NanT5iFSBZEF","colab_type":"text"},"source":["**Now** we remove the NaN values. This can be done with many methods, replacing with a number, taking the mean, min, max, dropping columns with NaN.\n","\n","\n","**Tip use**: \n","```pyhton\n","x_train.fillna()\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"dnMDyKFSBYi-","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7W0xJKFu3Qjl","colab_type":"text"},"source":["The we replace the -1 with 0, since -1 is not allowed in our network.\n","\n"]},{"cell_type":"code","metadata":{"id":"Nr7E0mE5iEz0","colab_type":"code","colab":{}},"source":["# Find a \"replace\" function from numpy \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sI8HnGq73b36","colab_type":"text"},"source":["We need to extract the numpy arrays from the pandas dataframe. \n","\n","Moreover, we only need the labes and not timestamp. "]},{"cell_type":"code","metadata":{"id":"R9lceZI7ChBr","colab_type":"code","colab":{}},"source":["x_train_np, x_test_np, y_train_np, y_test_np = x_train.to_numpy(copy=True), x_test.to_numpy(copy=True), y_train[0].to_numpy(copy=True), y_test[0].to_numpy(copy=True)   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WMx4YdaF3q3A","colab_type":"text"},"source":["Lets normalise the data \n","\n","Notice we use the same normalised values from the training to the testing"]},{"cell_type":"code","metadata":{"id":"jP7ykNkXLVFZ","colab_type":"code","colab":{}},"source":["# e.g. use StanderdScaler()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wCuhJw9yPqA6","colab_type":"text"},"source":["Know we can actually begind to try to classify it.\n","\n","Build you model again below (or use somehting completely different)"]},{"cell_type":"code","metadata":{"id":"oO9Uozl8PWsI","colab_type":"code","colab":{}},"source":["input_shape = (590,1) \n","classes = 2\n","\n","model = tf.keras.Sequential([\n","    tf.keras.Input(shape=input_shape),\n","    # You know the drill here \n","    tf.keras.layers.Dense(classes, activation=\"softmax\"), # Output layer\n","])\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"brsXaSv2RBeo","colab_type":"code","colab":{}},"source":["loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","model.compile(optimizer='adam',\n","                  loss=loss_fn,\n","                  metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9o1t81p8RCvi","colab_type":"code","colab":{}},"source":["model.fit(x_train_np, y_train_np, batch_size=512, epochs=200)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d0hT2TO_39gS","colab_type":"text"},"source":["Lets see how it performs"]},{"cell_type":"code","metadata":{"id":"ioe98Mwao1It","colab_type":"code","colab":{}},"source":["model.evaluate(x_test_np, y_test_np)"],"execution_count":null,"outputs":[]}]}